{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5f5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbea6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract sequence features -- BLOSUM62\n",
    "def BLOSUM62(sequences):\n",
    "    blosum62 = {\n",
    "        'A': [4,  -1, -2, -2, 0,  -1, -1, 0, -2,  -1, -1, -1, -1, -2, -1, 1,  0,  -3, -2, 0],  # A\n",
    "        'R': [-1, 5,  0,  -2, -3, 1,  0,  -2, 0,  -3, -2, 2,  -1, -3, -2, -1, -1, -3, -2, -3], # R\n",
    "        'N': [-2, 0,  6,  1,  -3, 0,  0,  0,  1,  -3, -3, 0,  -2, -3, -2, 1,  0,  -4, -2, -3], # N\n",
    "        'D': [-2, -2, 1,  6,  -3, 0,  2,  -1, -1, -3, -4, -1, -3, -3, -1, 0,  -1, -4, -3, -3], # D\n",
    "        'C': [0,  -3, -3, -3, 9,  -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1], # C\n",
    "        'Q': [-1, 1,  0,  0,  -3, 5,  2,  -2, 0,  -3, -2, 1,  0,  -3, -1, 0,  -1, -2, -1, -2], # Q\n",
    "        'E': [-1, 0,  0,  2,  -4, 2,  5,  -2, 0,  -3, -3, 1,  -2, -3, -1, 0,  -1, -3, -2, -2], # E\n",
    "        'G': [0,  -2, 0,  -1, -3, -2, -2, 6,  -2, -4, -4, -2, -3, -3, -2, 0,  -2, -2, -3, -3], # G\n",
    "        'H': [-2, 0,  1,  -1, -3, 0,  0,  -2, 8,  -3, -3, -1, -2, -1, -2, -1, -2, -2, 2,  -3], # H\n",
    "        'I': [-1, -3, -3, -3, -1, -3, -3, -4, -3, 4,  2, -3, 1,  0, -3, -2, -1, -3, -1, 3],  # I\n",
    "        'L': [-1, -2, -3, -4, -1, -2, -3, -4, -3, 2,  4,  -2, 2,  0, -3, -2, -1, -2, -1, 1],  # L\n",
    "        'K': [-1, 2,  0,  -1, -3, 1,  1,  -2, -1, -3, -2, 5,  -1, -3, -1, 0,  -1, -3, -2, -2], # K\n",
    "        'M': [-1, -1, -2, -3, -1, 0,  -2, -3, -2, 1,  2,  -1, 5,  0, -2, -1, -1, -1, -1, 1],  # M\n",
    "        'F': [-2, -3, -3, -3, -2, -3, -3, -3, -1, 0,  0,  -3, 0,  6, -4, -2, -2, 1,  3,  -1], # F\n",
    "        'P': [-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4, 7,  -1, -1, -4, -3, -2], # P\n",
    "        'S': [1,  -1, 1,  0,  -1, 0,  0,  0,  -1, -2, -2, 0,  -1, -2, -1, 4,  1,  -3, -2, -2], # S\n",
    "        'T': [0,  -1, 0,  -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1, 1,  5,  -2, -2, 0],  # T\n",
    "        'W': [-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1, 1, -4, -3, -2, 11, 2,  -3], # W\n",
    "        'Y': [-2, -2, -2, -3, -2, -1, -2, -3, 2,  -1, -1, -2, -1, 3, -3, -2, -2, 2,  7,  -1], # Y\n",
    "        'V': [0,  -3, -3, -3, -1, -2, -2, -3, -3, 3,  1,  -2, 1,  -1, -2, -2, 0,  -3, -1, 4],  # V\n",
    "        '*': [0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],  # *\n",
    "        'X': [0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],  # X\n",
    "        'U': [0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],  # U\n",
    "        '_': [0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],  # _\n",
    "    }\n",
    "    encodings = []\n",
    "    for sequence in sequences:\n",
    "        code=[]  \n",
    "        for j in sequence:\n",
    "            code = code + blosum62[j]\n",
    "        encodings.append(np.array(code))       \n",
    "    return encodings\n",
    "\n",
    "# Function to assign pathway and PPI encoding to corresponding items\n",
    "def Embedding(feature, data, D):\n",
    "\n",
    "    item =[]\n",
    "    for i in range(0, len(data)):\n",
    "        if data[\"SubID\"][i] in feature.keys():\n",
    "            item.append(feature[data[\"SubID\"][i]])\n",
    "        else:\n",
    "            item.append(np.array([0]*D))\n",
    "            \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b9b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python phosphorylation_prediction.py SVM Q9Y243 input.csv\n",
    "model_type = sys.argv[1]\n",
    "kinase = sys.argv[2]\n",
    "filename = sys.argv[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45df7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(filename)\n",
    "except:\n",
    "    print(\"File name error: the name of input file should be specified as input.csv !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e7c72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 10:10:10.505742: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"SVM\":\n",
    "    X_seq_validate = np.array(BLOSUM62(df[\"sequence\"]))\n",
    "    filename=\"../3_pretrained models/SVM/\"+ kinase +\"_SVM_model.sav\"\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    result = loaded_model.predict(X_seq_validate)\n",
    "    df[\"predict (1-yes and 0-no)\"] = result\n",
    "    df.to_csv(\"./predicted results by kinase\"+ kinase + \" SVM.csv\")\n",
    "    \n",
    "    \n",
    "elif model_type == \"DL\":\n",
    "    \n",
    "    # a dictionary\n",
    "    pathway = np.load(\"../1_features/path_embedding.npy\", allow_pickle=True)\n",
    "    pathway = pathway.flat[0]\n",
    "\n",
    "    # a dictionary\n",
    "    PPI = np.load(\"../1_features/sdne_embedding.npy\", allow_pickle=True)\n",
    "    PPI = PPI.flat[0]    \n",
    "    \n",
    "    #Sequence\n",
    "    X_seq_validate = np.array(BLOSUM62(df[\"sequence\"]))\n",
    "    #ppi\n",
    "    X_ppi_validate = np.array(Embedding(PPI, df, 128))\n",
    "    #pathway\n",
    "    X_path_validate = np.array(Embedding(pathway, df, 347))\n",
    "    \n",
    "    filename=\"../3_pretrained models/FCNN_LSTM/\"+ kinase +\"_DL_model.sav\"\n",
    "    model_combined = pickle.load(open(filename, 'rb'))    \n",
    "\n",
    "    validate_output = model_combined.predict([X_seq_validate.reshape(len(X_seq_validate), 1, 300), X_path_validate, X_ppi_validate])\n",
    "    pred = np.array(np.concatenate(np.where(validate_output > 0.5, 1, 0)).flat)   \n",
    "    df[\"predict (1-yes and 0-no)\"] = pred\n",
    "    df.to_csv(\"./predicted results by kinase\"+ kinase + \" FCNN_LSTM model.csv\")  \n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Error: Model type should be specified as either SVM or DL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429868a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
